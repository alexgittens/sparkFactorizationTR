We conclude our study of matrix factorizations at scale with the following take-away messages: 
\begin{itemize}
\item{A range of important matrix factorization algorithms can be implemented in Spark: we have successfully applied NMF, PCA and CX to TB-sized datasets. We have scaled the codes on 50, 100, 300, 500, and 1600 XC40 nodes. To the best of our knowledge, these are some of the largest scale \emph{scientific data analytics} workloads attempted with Spark.}
\item{Spark and C+MPI head-to-head comparisons of these methods have revealed a number of opportunities for improving Spark performance. The current end-to-end performance gap for our workloads is $2\times - 25\times$; and $10\times - 40\times$ without I/O. At scale, Spark performance overheads associated with scheduling, stragglers, result serialization and task deserialization dominate the runtime by an order of magnitude.}
\item{{In order for Spark to leverage existing, high-performance linear algebra libraries, it may be worthwhile to investigate better mechanisms for integrating and interfacing with MPI-based runtimes with Spark. The cost associated with copying data between the runtimes may not be prohibitive.}}
\item{Finally, efficient, parallel I/O is critical for Data Analytics at scale. HPC system architectures will need to be balanced to support data-intensive workloads.}
\end{itemize}